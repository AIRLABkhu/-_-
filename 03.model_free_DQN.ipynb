{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c931656b",
      "metadata": {
        "id": "c931656b"
      },
      "source": [
        "# 필수 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bfc3a3d",
      "metadata": {
        "id": "1bfc3a3d"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import collections\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "o_jpjK7NwgbZ"
      },
      "id": "o_jpjK7NwgbZ"
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "learning_rate = 5*1e-5\n",
        "gamma         = 0.99\n",
        "buffer_limit  = 10000\n",
        "batch_size    = 32"
      ],
      "metadata": {
        "id": "Drrk1-xewgzJ"
      },
      "id": "Drrk1-xewgzJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "829adf61",
      "metadata": {
        "id": "829adf61"
      },
      "source": [
        "# Grid World"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10223069",
      "metadata": {
        "id": "10223069"
      },
      "outputs": [],
      "source": [
        "# model 설정\n",
        "# 4x4, state는 (x, y), H:hole, G:goal\n",
        "# reward: goal:1 이며 나머지는 0\n",
        "#\n",
        "#     0  1  2  3\n",
        "#     4  H  6  H\n",
        "#     8  9 10  H\n",
        "#     H 12 13  G\n",
        "#\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a == 0:\n",
        "            self.move_left()\n",
        "        elif a == 1:\n",
        "            self.move_down()\n",
        "        elif a == 2:\n",
        "            self.move_right()\n",
        "        elif a == 3:\n",
        "            self.move_up()\n",
        "\n",
        "        if self.x == 3 and self.y == 3:\n",
        "            reward = 1\n",
        "        else:\n",
        "            reward = 0\n",
        "\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_down(self):\n",
        "        self.y += 1\n",
        "        if self.y > 3:\n",
        "            self.y = 3\n",
        "\n",
        "    def move_up(self):\n",
        "        self.y -= 1\n",
        "        if self.y < 0:\n",
        "            self.y = 0\n",
        "\n",
        "    def move_left(self):\n",
        "        self.x -= 1\n",
        "        if self.x < 0:\n",
        "            self.x = 0\n",
        "\n",
        "    def move_right(self):\n",
        "        self.x += 1\n",
        "        if self.x > 3:\n",
        "            self.x = 3\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x == 3 and self.y == 3:\n",
        "            return True\n",
        "        elif self.x == 0 and self.y == 3:\n",
        "            return True\n",
        "        elif self.x == 1 and self.y == 1:\n",
        "            return True\n",
        "        elif self.x == 3 and self.y == 1:\n",
        "            return True\n",
        "        elif self.x == 3 and self.y == 2:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.x, self.y)\n",
        "\n",
        "    def reset(self):\n",
        "        # Random Initialize\n",
        "\n",
        "        start = [(0, 0), (1, 0), (2, 0), (3, 0), (0, 1), (2, 1), (2, 0), (2, 1), (2, 2), (3, 1), (3, 2)]\n",
        "        (self.x,self.y)=random.choice(start)\n",
        "        return (self.x, self.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replay Buffer"
      ],
      "metadata": {
        "id": "Ezzlm2Ngwvqz"
      },
      "id": "Ezzlm2Ngwvqz"
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self):\n",
        "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
        "\n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self, n):\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            s, a, r, s_prime, done_mask = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask_lst.append([done_mask])\n",
        "\n",
        "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "               torch.tensor(done_mask_lst)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)"
      ],
      "metadata": {
        "id": "aYJrnB4Zwwlz"
      },
      "id": "aYJrnB4Zwwlz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network"
      ],
      "metadata": {
        "id": "au60CQ9Xw6Db"
      },
      "id": "au60CQ9Xw6Db"
    },
    {
      "cell_type": "code",
      "source": [
        "class Qnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Qnet, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def sample_action(self, s, epsilon):\n",
        "        out = self.forward(s)\n",
        "        coin = random.random()\n",
        "        if coin < epsilon:\n",
        "            return random.randint(0, 3)\n",
        "        else:\n",
        "            return out.argmax().item()\n",
        "\n",
        "    def max_action(self, s):\n",
        "        out = self.forward(s)\n",
        "        return out.argmax().item()"
      ],
      "metadata": {
        "id": "IcDck0E-w59t"
      },
      "id": "IcDck0E-w59t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "HeLea9TqxBHh"
      },
      "id": "HeLea9TqxBHh"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(q, q_target, memory, optimizer):\n",
        "    for i in range(10):\n",
        "        s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
        "\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(1, a)\n",
        "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "        target = r + gamma * max_q_prime * done_mask\n",
        "        loss = F.smooth_l1_loss(q_a, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "r3lBWcJ9xBBf"
      },
      "id": "r3lBWcJ9xBBf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DQN"
      ],
      "metadata": {
        "id": "bXsD4O3pxFXC"
      },
      "id": "bXsD4O3pxFXC"
    },
    {
      "cell_type": "code",
      "source": [
        "def DQN():\n",
        "    env = GridWorld()\n",
        "    q = Qnet()\n",
        "    q_target = Qnet()\n",
        "    memory = ReplayBuffer()\n",
        "\n",
        "    print_interval = 100\n",
        "    score = 0.0\n",
        "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
        "\n",
        "    for n_epi in range(10000):\n",
        "        epsilon = max(0.1, 0.3 - 0.01 * (n_epi / 200))\n",
        "        done = False\n",
        "\n",
        "        s = np.asarray(env.reset())\n",
        "        while not done:\n",
        "            a = q.sample_action(torch.from_numpy(s).float(), epsilon)\n",
        "            (x_prime, y_prime), reward, done = env.step(a)\n",
        "            s_prime =  np.array([x_prime, y_prime])\n",
        "            done_mask = 0.0 if done else 1.0\n",
        "            memory.put((s, a, reward, s_prime, done_mask))\n",
        "            s = s_prime\n",
        "            score += reward\n",
        "            if done:\n",
        "                break\n",
        "        if memory.size() > 1000:\n",
        "            train(q, q_target, memory, optimizer)\n",
        "\n",
        "        if n_epi % print_interval == 0 and n_epi != 0:\n",
        "            q_target.load_state_dict(q.state_dict())\n",
        "            print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
        "                n_epi, score / print_interval, memory.size(), epsilon * 100))\n",
        "            score = 0.0\n",
        "\n",
        "    # print policy\n",
        "    for r in range(4):\n",
        "        for c in range(4):\n",
        "            s = np.array([c, r])\n",
        "            a = q.max_action(torch.from_numpy(s).float())\n",
        "            if c == 3 and r == 3:\n",
        "                str = 'G'\n",
        "            elif c == 0 and r == 3:\n",
        "                str = 'H'\n",
        "            elif c == 1 and r == 1:\n",
        "                str = 'H'\n",
        "            elif c == 3 and r == 1:\n",
        "                str = 'H'\n",
        "            elif c == 3 and r == 2:\n",
        "                str = 'H'\n",
        "            else:\n",
        "                if a == 0:\n",
        "                    str = '<'\n",
        "                elif a == 1:\n",
        "                    str = 'v'\n",
        "                elif a == 2:\n",
        "                    str = '>'\n",
        "                elif a == 3:\n",
        "                    str = '^'\n",
        "            print('%03s  '%str, end='')\n",
        "        print('')"
      ],
      "metadata": {
        "id": "H0LWXtLnxFRy"
      },
      "id": "H0LWXtLnxFRy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "pmxp_nwqxKAq"
      },
      "id": "pmxp_nwqxKAq"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    DQN()"
      ],
      "metadata": {
        "id": "cB2zq1OLxJ63"
      },
      "id": "cB2zq1OLxJ63",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "03.model_free_DQN.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}